prix<-db2$get_query(paste0("SELECT  * FROM dbo.timeseries_data data_tab INNER JOIN dbo.timeseries_list key_tab ON data_tab.fk_idl = key_tab.pk_idl WHERE key_tab.source = 'ENTSOE_API' AND key_tab.level_2 = 'price' AND data_tab.start_datetime > '", as.character(date_min, format = "%d/%m/%Y"),"'"))
prix<-dcast(prix[level_3=='FR'], start_datetime ~ level_3,value.var='value',fun=sum)
setnames(prix,'FR','Prix_Spot')
future_peak<- db$get_query(paste("SELECT Dt, Prix_compensation FROM [DB_PROD_BASECRE].[Surveillance].[prixfutur] where Profil='Pointe' and produit='Q' and annee=year(Dt)+1 and month(Datedebut_Livraison)=1 and Dt >= '",  as.character(date_min, format = "%d/%m/%Y"), "' and Dt < '", as.character(date_max, format = "%d/%m/%Y"), "'"))
#Prix future à venir
setnames(future_peak,'Prix_compensation','PrixPeak')
setnames(future_peak,'Dt','Date')
#Import des données (la table [BdintercoSQL].[dbo].[PROGRAMME_ECHANGE] ou l'API RTE n'a pas assez d'historique )
#Calcul des imports/exports, on utilise également opendata réseaux. Les données de la table Programme d'Appel ne semblent pas boucler
#https://opendata.reseaux-energies.fr/explore/dataset/imports-exports-commerciaux/api/?sort=date
flux_comm<-fread('imports-exports-commerciaux.csv')
setnames(flux_comm,"Tranche horaire du programme d'Ã©change","hour")
flux_comm<-flux_comm[,start_datetime:=as.POSIXct(Date,tz="Europe/Paris")+(hour-1)*60*60]
border = c("CH", "GB","CWE","IT","SP")
flux_comm<-flux_comm[,(border) := list(`FR vers CH (MWh)`+`CH vers FR (MWh)`,`FR vers GB (MWh)`+`GB vers FR (MWh)`,`FR vers CWE (MWh)`+`CWE vers FR (MWh)`,`FR vers IT (MWh)`+`IT vers FR (MWh)`,`FR vers ES (MWh)`+`ES vers FR (MWh)`)][,.(start_datetime,CH, GB,CWE,IT,SP)]
echange <- db2$get_query(paste0("SELECT  * FROM dbo.timeseries_data data_tab INNER JOIN dbo.timeseries_list key_tab ON data_tab.fk_idl = key_tab.pk_idl WHERE key_tab.source = 'ENTSOE_API' AND key_tab.level_1 = 'interco' AND  key_tab.level_2 = 'da_sch_exch' AND data_tab.start_datetime > '", as.character(date_min, format = "%d/%m/%Y"),"'"))
#On somme les positions import et export. IL semble qu'il existe un traitement pour l'agrégation de la BE et DE. Je n'ai pas trouvé la bonne manière de dissocier import et export par rapport à l'ancien format de fichier
echange<-echange[start_datetime>as.POSIXct("2021-01-01")]
echange<-echange[level_3 %in% c("DE","BE"),level_3:="CWE"]
echange<-echange[level_4 %in% c("DE","BE"),level_4:="CWE"]
echange<-echange[, type:=paste(level_3,level_4,sep=" vers ")]
echange<-dcast(echange, start_datetime ~ type,value.var='value',fun=sum)
#Netting
echange<-echange[,(border) := list(`FR vers CH`-`CH vers FR`,`FR vers GB`-`GB vers FR`,`FR vers CWE`-`CWE vers FR`,`FR vers IT`-`IT vers FR`,`FR vers SP`-`SP vers FR`)][,.(start_datetime,CH, GB,CWE,IT,SP)]
flux_comm<- rbind(flux_comm,echange,fill=TRUE)
#aggregation des données
prix_agg<-Reduce(function(x,y) merge(x = x, y = y, by = "Date"), list(price_co2, gaz_price, coal_price,brent_price))
prix_agg$Date<-lubridate::force_tz(prix_agg$Date,tzone="Europe/Paris")
prix_agg<-merge(prix_agg,future_peak,by = "Date")
#aggregation des données
dt_agg<-Reduce(function(x,y) merge(x = x, y = y, by = "start_datetime"), list(conso, prod, ind1,flux_comm,prix,water))
dt_agg<- dt_agg[,Date:=floor_date(start_datetime,unit='day')]
dt_agg<-prix_agg[dt_agg,on=.(Date)][,Date:=NULL]
dt_agg<-setnafill(dt_agg, type="locf")
dt_agg<-na.omit(dt_agg)
saveRDS(dt_agg,"donnee_regression")
write.csv(dt_agg,file="data_spot.csv")
# On applique le modèle linéaire à toutes les heures, puis seulement sur le spot lisse
dt_agg<-readRDS("donnee_regression")
cols<-names(which(unlist(lapply(dt_agg, is.numeric))))
dt_agg_scale<-copy(dt_agg)
dt_agg_scale<-dt_agg_scale[, (cols):= lapply(.SD, scale), .SDcols=cols]
dt_agg_past<-copy(dt_agg_scale[start_datetime<as.POSIXct('2021-01-01')])
dt_agg_new<-copy(dt_agg_scale[start_datetime>as.POSIXct('2021-01-01')])
model <- lm (data=dt_agg_past, Prix_Spot ~ . - start_datetime )
summary(model)
y = predict(model,dt_agg_scale)
dt_lm<-cbind(dt_agg_scale,y)
dt_lm<-dt_lm[,delta:=Prix_Spot-y]
fig<- plot_ly(dt_lm)
fig<- fig %>% add_trace(x=~start_datetime,y=~Prix_Spot,type="scatter",mode="markers")
fig<- fig %>% add_trace(x=~start_datetime,y=~y,type="scatter",mode="lines")fit
fig<- plot_ly(dt_lm)
fig<- fig %>% add_trace(x=~start_datetime,y=~Prix_Spot,type="scatter",mode="markers")
fig<- fig %>% add_trace(x=~start_datetime,y=~y,type="scatter",mode="lines")
fig<- fig %>% add_trace(x=~start_datetime,y=~delta,type="scatter",mode="lines")
fig
#Spot horaire
dt_agg_scale_h<-copy(dt_agg)
dt_agg_scale_h<-dt_agg_scale_h[,lapply(.SD, mean),by=floor_date(start_datetime,unit='day')]
dt_agg_scale_h<-dt_agg_scale_h[, (cols):= lapply(.SD, scale), .SDcols=cols]
setnames(dt_agg_scale_h,"floor_date","start_datetime")
dt_agg_past_h<-copy(dt_agg_scale_h[start_datetime<as.POSIXct('2021-01-01')])
dt_agg_new_h<-copy(dt_agg_scale_h[start_datetime>as.POSIXct('2021-01-01')])
model_h <- lm (data=dt_agg_past_h, Prix_Spot ~ . - start_datetime)
summary(model_h)
y = predict(model_h,dt_agg_scale_h)
dt_lm_h<-cbind(dt_agg_scale_h,y)
dt_lm_h[,delta:=Prix_Spot-y]
fig<- plot_ly(dt_lm_h)
fig<- fig %>% add_trace(x=~start_datetime,y=~Prix_Spot,type="scatter",mode="markers")
fig<- fig %>% add_trace(x=~start_datetime,y=~y,type="scatter",mode="lines")
fig<- fig %>% add_trace(x=~start_datetime,y=~delta,type="scatter",mode="lines")
fig
dt_agg<-readRDS("donnee_regression")
cols<-names(which(unlist(lapply(dt_agg, is.numeric))))
dt_agg_scale<-copy(dt_agg)
dt_agg_scale<-dt_agg_scale[, (cols):= lapply(.SD, scale), .SDcols=cols]
library(caret)
dt_agg_past<-copy(dt_agg_scale[start_datetime<as.POSIXct('2021-10-01')])
# creating training data as 80% of the dataset
random_sample <- createDataPartition(dt_agg_past$Prix_Spot,
p = 0.7, list = FALSE)
# generating training dataset
# from the random_sample
training_dataset  <- dt_agg_past[random_sample, ]
# generating testing dataset
# from rows which are not
# included in random_sample
testing_dataset <- dt_agg_past[-random_sample, ]
# Building the model
# training the model
Msvm <- fit(Prix_Spot ~ . - start_datetime, data=training_dataset, model="svm", kpar=list(sigma=0.10), C=1)
# predicting the target variable
predictions <- predict(Msvm, testing_dataset)
print(mmetric(testing_dataset$Prix_Spot,predictions,"R2"))
importance_past<- Importance(Msvm, data=training_dataset)
importance_past<-cbind(names(training_dataset),importance_past[["imp"]])
P = predict(Msvm,dt_agg_scale)
dt_agg_n_y<-cbind(dt_agg_scale,P)
#
#
#
fig<- plot_ly(dt_agg_n_y)
#
fig<- fig %>% add_trace(x=~start_datetime,y=~Prix_Spot,type="scatter",mode="markers")
#
fig<- fig %>% add_trace(x=~start_datetime,y=~P,type="scatter",mode="lines")
#
fig
dt_agg_past<-copy(dt_agg_scale[start_datetime<as.POSIXct('2021-11-01')])
# creating training data as 80% of the dataset
random_sample <- createDataPartition(dt_agg_past$Prix_Spot,
p = 0.7, list = FALSE)
# generating training dataset
# from the random_sample
training_dataset  <- dt_agg_past[random_sample, ]
# generating testing dataset
# from rows which are not
# included in random_sample
testing_dataset <- dt_agg_past[-random_sample, ]
# Building the model
# training the model
Msvm <- fit(Prix_Spot ~ . - start_datetime, data=training_dataset, model="svm", kpar=list(sigma=0.10), C=1)
# predicting the target variable
predictions <- predict(Msvm, testing_dataset)
print(mmetric(testing_dataset$Prix_Spot,predictions,"R2"))
importance_past<- Importance(Msvm, data=training_dataset)
importance_past<-cbind(names(training_dataset),importance_past[["imp"]])
P = predict(Msvm,dt_agg_scale)
dt_agg_n_y<-cbind(dt_agg_scale,P)
#
#
#
fig<- plot_ly(dt_agg_n_y)
#
fig<- fig %>% add_trace(x=~start_datetime,y=~Prix_Spot,type="scatter",mode="markers")
#
fig<- fig %>% add_trace(x=~start_datetime,y=~P,type="scatter",mode="lines")
#
fig
View(importance_past)
#
library(caret)
dt_agg<-readRDS("donnee_regression")
cols<-names(which(unlist(lapply(dt_agg, is.numeric))))
dt_agg_scale<-copy(dt_agg)
dt_agg_scale<-dt_agg_scale[, (cols):= lapply(.SD, scale), .SDcols=cols]
dt_agg_past<-copy(dt_agg_scale[start_datetime<as.POSIXct('2020-01-01')])
# creating training data as 80% of the dataset
random_sample <- createDataPartition(dt_agg_past$Prix_Spot,
p = 0.7, list = FALSE)
# generating training dataset
# from the random_sample
training_dataset  <- dt_agg_past[random_sample, ]
# generating testing dataset
# from rows which are not
# included in random_sample
testing_dataset <- dt_agg_past[-random_sample, ]
# Building the model
# training the model
Msvm <- fit(Prix_Spot ~ . - start_datetime, data=training_dataset, model="svm", kpar=list(sigma=0.10), C=1)
# predicting the target variable
predictions <- predict(Msvm, testing_dataset)
print(mmetric(testing_dataset$Prix_Spot,predictions,"R2"))
importance_past<- Importance(Msvm, data=training_dataset)
importance_past<-cbind(names(training_dataset),importance_past[["imp"]])
P = predict(Msvm,dt_agg_scale)
dt_agg_n_y<-cbind(dt_agg_scale,P)
#
#
#
fig<- plot_ly(dt_agg_n_y)
#
fig<- fig %>% add_trace(x=~start_datetime,y=~Prix_Spot,type="scatter",mode="markers")
#
fig<- fig %>% add_trace(x=~start_datetime,y=~P,type="scatter",mode="lines")
#
fig
#
dt_agg<-readRDS("donnee_regression")
cols<-names(which(unlist(lapply(dt_agg, is.numeric))))
dt_agg_scale<-copy(dt_agg)
dt_agg_scale<-dt_agg_scale[, (cols):= lapply(.SD, scale), .SDcols=cols]
dt_agg_past<-copy(dt_agg_scale[start_datetime<as.POSIXct('2020-01-01')])
# creating training data as 80% of the dataset
random_sample <- createDataPartition(dt_agg_past$Prix_Spot,
p = 0.7, list = FALSE)
# generating training dataset
# from the random_sample
training_dataset  <- dt_agg_past[random_sample, ]
# generating testing dataset
# from rows which are not
# included in random_sample
testing_dataset <- dt_agg_past[-random_sample, ]
# Building the model
# training the model
Msvm <- fit(Prix_Spot ~ . - start_datetime, data=training_dataset, model="svm", kernel="tanhdot")
# predicting the target variable
predictions <- predict(Msvm, testing_dataset)
print(mmetric(testing_dataset$Prix_Spot,predictions,"R2"))
importance_past<- Importance(Msvm, data=training_dataset)
importance_past<-cbind(names(training_dataset),importance_past[["imp"]])
P = predict(Msvm,dt_agg_scale)
dt_agg_n_y<-cbind(dt_agg_scale,P)
#
#
#
fig<- plot_ly(dt_agg_n_y)
#
fig<- fig %>% add_trace(x=~start_datetime,y=~Prix_Spot,type="scatter",mode="markers")
#
fig<- fig %>% add_trace(x=~start_datetime,y=~P,type="scatter",mode="lines")
#
fig
#
Building the model
# training the model
Msvm <- fit(Prix_Spot ~ . - start_datetime, data=training_dataset, model="svm", kernel="polydot")
# predicting the target variable
predictions <- predict(Msvm, testing_dataset)
print(mmetric(testing_dataset$Prix_Spot,predictions,"R2"))
importance_past<- Importance(Msvm, data=training_dataset)
importance_past<-cbind(names(training_dataset),importance_past[["imp"]])
P = predict(Msvm,dt_agg_scale)
dt_agg_n_y<-cbind(dt_agg_scale,P)
#
#
#
fig<- plot_ly(dt_agg_n_y)
#
fig<- fig %>% add_trace(x=~start_datetime,y=~Prix_Spot,type="scatter",mode="markers")
#
fig<- fig %>% add_trace(x=~start_datetime,y=~P,type="scatter",mode="lines")
#
fig
# training the model
Msvm <- fit(Prix_Spot ~ . - start_datetime, data=training_dataset, model="svm", kpar=list(sigma=0.01), C=0.1)
# predicting the target variable
predictions <- predict(Msvm, testing_dataset)
print(mmetric(testing_dataset$Prix_Spot,predictions,"R2"))
importance_past<- Importance(Msvm, data=training_dataset)
importance_past<-cbind(names(training_dataset),importance_past[["imp"]])
P = predict(Msvm,dt_agg_scale)
dt_agg_n_y<-cbind(dt_agg_scale,P)
#
#
#
fig<- plot_ly(dt_agg_n_y)
#
fig<- fig %>% add_trace(x=~start_datetime,y=~Prix_Spot,type="scatter",mode="markers")
#
fig<- fig %>% add_trace(x=~start_datetime,y=~P,type="scatter",mode="lines")
#
fig
#
# training the model
Msvm <- fit(Prix_Spot ~ . - start_datetime, data=training_dataset, model="svm", kpar=list(sigma=0.01), C=10)
# predicting the target variable
predictions <- predict(Msvm, testing_dataset)
print(mmetric(testing_dataset$Prix_Spot,predictions,"R2"))
importance_past<- Importance(Msvm, data=training_dataset)
importance_past<-cbind(names(training_dataset),importance_past[["imp"]])
P = predict(Msvm,dt_agg_scale)
dt_agg_n_y<-cbind(dt_agg_scale,P)
#
#
#
fig<- plot_ly(dt_agg_n_y)
#
fig<- fig %>% add_trace(x=~start_datetime,y=~Prix_Spot,type="scatter",mode="markers")
#
fig<- fig %>% add_trace(x=~start_datetime,y=~P,type="scatter",mode="lines")
#
fig
dt_agg_past<-copy(dt_agg_scale[start_datetime<as.POSIXct('2021-11-01')])
# creating training data as 80% of the dataset
random_sample <- createDataPartition(dt_agg_past$Prix_Spot,
p = 0.7, list = FALSE)
# generating training dataset
# from the random_sample
training_dataset  <- dt_agg_past[random_sample, ]
# generating testing dataset
# from rows which are not
# included in random_sample
testing_dataset <- dt_agg_past[-random_sample, ]
# Building the model
# training the model
Msvm <- fit(Prix_Spot ~ . - start_datetime, data=training_dataset, model="svm", kpar=list(sigma=0.01), C=10)
# predicting the target variable
predictions <- predict(Msvm, testing_dataset)
print(mmetric(testing_dataset$Prix_Spot,predictions,"R2"))
importance_past<- Importance(Msvm, data=training_dataset)
importance_past<-cbind(names(training_dataset),importance_past[["imp"]])
P = predict(Msvm,dt_agg_scale)
dt_agg_n_y<-cbind(dt_agg_scale,P)
#
#
#
fig<- plot_ly(dt_agg_n_y)
#
fig<- fig %>% add_trace(x=~start_datetime,y=~Prix_Spot,type="scatter",mode="markers")
#
fig<- fig %>% add_trace(x=~start_datetime,y=~P,type="scatter",mode="lines")
#
fig
# training the model
Msvm <- fit(Prix_Spot ~ . - start_datetime, data=training_dataset, model="svm", kpar=list(sigma=0.0O01), C=10)
odel
Msvm <- fit(Prix_Spot ~ . - start_datetime, data=training_dataset, model="svm", kpar=list(sigma=0.0001), C=10)
# predicting the target variable
predictions <- predict(Msvm, testing_dataset)
print(mmetric(testing_dataset$Prix_Spot,predictions,"R2"))
importance_past<- Importance(Msvm, data=training_dataset)
importance_past<-cbind(names(training_dataset),importance_past[["imp"]])
P = predict(Msvm,dt_agg_scale)
dt_agg_n_y<-cbind(dt_agg_scale,P)
#
#
#
fig<- plot_ly(dt_agg_n_y)
#
fig<- fig %>% add_trace(x=~start_datetime,y=~Prix_Spot,type="scatter",mode="markers")
#
fig<- fig %>% add_trace(x=~start_datetime,y=~P,type="scatter",mode="lines")
#
fig
# training the model
Msvm <- fit(Prix_Spot ~ . - start_datetime, data=training_dataset, model="svm", kpar=list(sigma=0.001), C=10)
# predicting the target variable
predictions <- predict(Msvm, testing_dataset)
print(mmetric(testing_dataset$Prix_Spot,predictions,"R2"))
importance_past<- Importance(Msvm, data=training_dataset)
importance_past<-cbind(names(training_dataset),importance_past[["imp"]])
P = predict(Msvm,dt_agg_scale)
dt_agg_n_y<-cbind(dt_agg_scale,P)
#
#
#
fig<- plot_ly(dt_agg_n_y)
#
fig<- fig %>% add_trace(x=~start_datetime,y=~Prix_Spot,type="scatter",mode="markers")
#
fig<- fig %>% add_trace(x=~start_datetime,y=~P,type="scatter",mode="lines")
#
fig
View(importance_past)
View(ind)
View(importance_past)
Msvm <- fit(Prix_Spot ~ . - start_datetime-PrixPeak, data=training_dataset, model="svm", kpar=list(sigma=0.1), C=1)
# predicting the target variable
predictions <- predict(Msvm, testing_dataset)
print(mmetric(testing_dataset$Prix_Spot,predictions,"R2"))
importance_past<- Importance(Msvm, data=training_dataset)
importance_past<-cbind(names(training_dataset),importance_past[["imp"]])
P = predict(Msvm,dt_agg_scale)
dt_agg_n_y<-cbind(dt_agg_scale,P)
#
#
#
fig<- plot_ly(dt_agg_n_y)
#
fig<- fig %>% add_trace(x=~start_datetime,y=~Prix_Spot,type="scatter",mode="markers")
#
fig<- fig %>% add_trace(x=~start_datetime,y=~P,type="scatter",mode="lines")
#
fig
dt_agg_past<-copy(dt_agg_scale[start_datetime<as.POSIXct('2021-12-01')])
# creating training data as 80% of the dataset
random_sample <- createDataPartition(dt_agg_past$Prix_Spot,
p = 0.4, list = FALSE)
# generating training dataset
# from the random_sample
training_dataset  <- dt_agg_past[random_sample, ]
# generating testing dataset
# from rows which are not
# included in random_sample
testing_dataset <- dt_agg_past[-random_sample, ]
# Building the model
# training the model
Msvm <- fit(Prix_Spot ~ . - start_datetime-PrixPeak, data=training_dataset, model="svm", kpar=list(sigma=0.1), C=1)
# predicting the target variable
predictions <- predict(Msvm, testing_dataset)
print(mmetric(testing_dataset$Prix_Spot,predictions,"R2"))
importance_past<- Importance(Msvm, data=training_dataset)
importance_past<-cbind(names(training_dataset),importance_past[["imp"]])
P = predict(Msvm,dt_agg_scale)
dt_agg_n_y<-cbind(dt_agg_scale,P)
#
#
#
fig<- plot_ly(dt_agg_n_y)
#
fig<- fig %>% add_trace(x=~start_datetime,y=~Prix_Spot,type="scatter",mode="markers")
#
fig<- fig %>% add_trace(x=~start_datetime,y=~P,type="scatter",mode="lines")
#
fig
View(training_dataset)
he model before 2021
dt_agg_past<-copy(dt_agg_scale[start_datetime>as.POSIXct('2019-01-01')])
# creating training data as 80% of the dataset
random_sample <- createDataPartition(dt_agg_past$Prix_Spot,
p = 0.4, list = FALSE)
# generating training dataset
# from the random_sample
training_dataset  <- dt_agg_past[random_sample, ]
# generating testing dataset
# from rows which are not
# included in random_sample
testing_dataset <- dt_agg_past[-random_sample, ]
# Building the model
# training the model
Msvm <- fit(Prix_Spot ~ . - start_datetime-PrixPeak, data=training_dataset, model="svm", kpar=list(sigma=0.1), C=1)
# predicting the target variable
predictions <- predict(Msvm, testing_dataset)
print(mmetric(testing_dataset$Prix_Spot,predictions,"R2"))
importance_past<- Importance(Msvm, data=training_dataset)
importance_past<-cbind(names(training_dataset),importance_past[["imp"]])
P = predict(Msvm,dt_agg_scale)
dt_agg_n_y<-cbind(dt_agg_scale,P)
#
#
#
fig<- plot_ly(dt_agg_n_y)
#
fig<- fig %>% add_trace(x=~start_datetime,y=~Prix_Spot,type="scatter",mode="markers")
#
fig<- fig %>% add_trace(x=~start_datetime,y=~P,type="scatter",mode="lines")
#
fig
#
dt_agg_past<-copy(dt_agg_scale[start_datetime<as.POSIXct('2021-12-01')])
# creating training data as 80% of the dataset
random_sample <- createDataPartition(dt_agg_past$Prix_Spot,
p = 0.1, list = FALSE)
# generating training dataset
# from the random_sample
training_dataset  <- dt_agg_past[random_sample, ]
# generating testing dataset
# from rows which are not
# included in random_sample
testing_dataset <- dt_agg_past[-random_sample, ]
# Building the model
# training the model
Msvm <- fit(Prix_Spot ~ . - start_datetime-PrixPeak, data=training_dataset, model="svm", kpar=list(sigma=0.1), C=1)
# predicting the target variable
predictions <- predict(Msvm, testing_dataset)
print(mmetric(testing_dataset$Prix_Spot,predictions,"R2"))
importance_past<- Importance(Msvm, data=training_dataset)
importance_past<-cbind(names(training_dataset),importance_past[["imp"]])
P = predict(Msvm,dt_agg_scale)
dt_agg_n_y<-cbind(dt_agg_scale,P)
#
#
#
fig<- plot_ly(dt_agg_n_y)
#
fig<- fig %>% add_trace(x=~start_datetime,y=~Prix_Spot,type="scatter",mode="markers")
#
fig<- fig %>% add_trace(x=~start_datetime,y=~P,type="scatter",mode="lines")
#
fig
library(caret)
dt_agg<-readRDS("donnee_regression")
cols<-names(which(unlist(lapply(dt_agg, is.numeric))))
dt_agg_scale<-copy(dt_agg)
dt_agg_scale<-dt_agg_scale[, (cols):= lapply(.SD, scale), .SDcols=cols]
# creating training data as 80% of the dataset
random_sample <- createDataPartition(dt_agg_scale$Prix_Spot,
p = 0.7, list = FALSE)
# generating training dataset
# from the random_sample
training_dataset  <- dt_agg_scale[random_sample, ]
# generating testing dataset
# from rows which are not
# included in random_sample
testing_dataset <- dt_agg_scale[-random_sample, ]
# Building the model
# training the model
Msvm <- fit(Prix_Spot ~ . - start_datetime, data=training_dataset, model="svm", kpar=list(sigma=0.10), C=1)
# predicting the target variable
predictions <- predict(Msvm, testing_dataset)
print(mmetric(testing_dataset$Prix_Spot,predictions,"R2"))
importance<- Importance(Msvm, data=training_dataset)
importance<-cbind(names(training_dataset),importance[["imp"]])
#Building the model before 2021
dt_agg_past<-copy(dt_agg_scale[start_datetime<as.POSIXct('2021-12-01')])
# creating training data as 80% of the dataset
random_sample <- createDataPartition(dt_agg_past$Prix_Spot,
p = 0.7, list = FALSE)
# generating training dataset
# from the random_sample
training_dataset  <- dt_agg_past[random_sample, ]
# generating testing dataset
# from rows which are not
# included in random_sample
testing_dataset <- dt_agg_past[-random_sample, ]
# Building the model
# training the model
Msvm <- fit(Prix_Spot ~ . - start_datetime-PrixPeak, data=training_dataset, model="svm", kpar=list(sigma=0.1), C=1)
# predicting the target variable
predictions <- predict(Msvm, testing_dataset)
print(mmetric(testing_dataset$Prix_Spot,predictions,"R2"))
importance_past<- Importance(Msvm, data=training_dataset)
importance_past<-cbind(names(training_dataset),importance_past[["imp"]])
View(importance_past)
View(importance)
View(importance_past)
View(importance)
View(importance_past)
View(importance)
